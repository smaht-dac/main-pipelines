## Pipeline information #####################################
#     General information for the pipeline
#############################################################
name: Illumina_alignment_GRCh38
description: End-to-end alignment pipeline for paired-end Illumina data. |
             Run fastp to pre-process input FASTQ files and remove polyG artifacts. |
             Run Sentieon BWA-MEM for alignment, incorporate read groups, |
             mark duplicate reads, and recalibrate base and indel scores. |
             Sort the alignment BAM files by coordinates. |
             Merge the aligned BAM files. |
             Calculate quality metrics. |
             Implemented to run in distributed mode and |
             processing reads by lane, per single sample and library. |
             Build hg38/GRCh38

category:
  - Read Manipulation
  - Alignment
  - Quality Control

## General arguments ########################################
#     Pipeline input, reference files, and general arguments
#       define all arguments for the pipeline here
#############################################################
input:

  # File arguments
  input_files_r1_fastq_gz:
    argument_type: file.fastq_gz
    dimensionality: 1

  input_files_r2_fastq_gz:
    argument_type: file.fastq_gz
    dimensionality: 1

  # !! FASTQ files need to be organized by lanes as the following example:
  # -> input_files_r1_fastq_gz
  #   [ lane_0_r1, lane_1_r1, lane_2_r1, ... ]
  # -> input_files_r2_fastq_gz
  #   [ lane_0_r2, lane_1_r2, lane_2_r2, ... ]

  genome_reference_fasta:
    argument_type: file.fa
    files:
      - complete-reference-fasta-no-alt@GCA_000001405.15_GRCh38_no_decoy

  genome_reference_bwt:
    argument_type: file.bwt
    files:
      - complete-reference-bwt-no-alt@GCA_000001405.15_GRCh38_no_decoy

  known_sites_indel:
    argument_type: file.vcf_gz
    files:
      - mills-1000g-gold-standard-indel@GRCh38

  known_sites_snp:
    argument_type: file.vcf_gz
    files:
      - dbsnp-all@138_GRCh38

  shards_file:
    argument_type: file.txt
    files:
      - regions-200M-16shards@GCA_000001405.15_GRCh38_no_decoy

  interval_list:
    argument_type: file.interval_list
    files:
      - picard-chr22-interval-list@GCA_000001405.15_GRCh38_no_decoy

  resources_vb2:
    argument_type: file.vb2
    files:
      - verifybamid2-resources-1000g-100k@GRCh38

  # Parameter arguments
  sample_name:
    argument_type: parameter.string

  library_id:
    argument_type: parameter.string

  length_required:
    # Reads shorter than length_required will be discarded
    argument_type: parameter.integer

  shards_index:
    # These indexes need to match the number of shards in shards_file
    argument_type: parameter.array
    value: ["0", "1", "2", "3", "4", "5", "6", "7", "8", "9", "10", "11", "12", "13", "14", "15"]

  optical_dup_pix_dist:
    # The maximum offset between two duplicate clusters in order to consider them optical duplicates.
    # This should be set to 100 for (circa 2011+) read names and typical flowcells.
    # Structured flow cells (NovaSeq, HiSeq 4000, X) should use ~2500.
    # For older conventions, distances could be to some fairly small number (e.g. 5-10 pixels).
    argument_type: parameter.integer
    value: 2500

  # QC ruleset arguments
  qc_ruleset:
    argument_type: qc_ruleset.object
    qc_thresholds:
      freemix_alpha:
        rule: Estimate of Contamination [VerifyBamID2]|<|0.01|1
        flag: True
      duplicates:
        rule: Percentage of Reads Duplicated [Samtools]|<|15|100
        flag: True
      mapped:
        rule: Percentage of Reads Mapped [Samtools]|>|97|0
        flag: True
      mapped_proper_pairs:
        rule: Percentage of Properly Paired Reads [Samtools]|>|92|0
        flag: True
      mismatch_rate:
        rule: Aligned Bases Mismatch Rate [Picard]|<|0.008|1
        flag: True
      insert_size:
        rule: Mean Insert Size [Picard]|>|250|0
        flag: True
    qc_rule: "{freemix_alpha} and {duplicates} and {mapped} and {mapped_proper_pairs} and {mismatch_rate} and {insert_size}"

## Workflows and dependencies ###############################
#     Information for the workflows and their dependencies
#############################################################
workflows:

## Pre-processing ###########################################
#     Steps to pre-process input files
#       for alignment
#############################################################

  ## Workflow definition #####################
  #   fastp_paired-end
  ############################################
  fastp_paired-end:

    ## Specific arguments ##############
    ####################################
    input:

      # File argument
      input_file_r1_fastq_gz:
        argument_type: file.fastq_gz
        source_argument_name: input_files_r1_fastq_gz
        scatter: 1

      input_file_r2_fastq_gz:
        argument_type: file.fastq_gz
        source_argument_name: input_files_r2_fastq_gz
        scatter: 1

      # Parameter argument
      trim_poly_g:
        # Force polyG tail trimming
        argument_type: parameter.boolean
        value: True

      disable_quality_filtering:
        # If this option is specified, quality filtering is disabled
        argument_type: parameter.boolean
        value: True

      disable_adapter_trimming:
        # If this option is specified, adapter trimming is disabled
        argument_type: parameter.boolean
        value: True

      length_required:
        argument_type: parameter.integer

      nthreads:
        argument_type: parameter.integer
        value: 16

    ## Output ##########################
    #     Output files for the workflow
    ####################################
    output:

      # File output
      output_file_r1_fastq_gz:
        description: fastp pre-processed FASTQ
        read_pair_number: "R1"
        data_category:
          - Sequencing Reads
        data_type:
          - Unaligned Reads
        s3_lifecycle_category: no_storage

      output_file_r2_fastq_gz:
        description: fastp pre-processed FASTQ
        read_pair_number: "R2"
        data_category:
          - Sequencing Reads
        data_type:
          - Unaligned Reads
        s3_lifecycle_category: no_storage

      output_file_json:
        description: fastp summary JSON
        data_category:
          - Quality Control
        data_type:
          - Statistics

      output_file_failed_fastq_gz:
        description: fastp failed reads FASTQ
        data_category:
          - Sequencing Reads
        data_type:
          - Unaligned Reads

    ## EC2 Configuration to use ########
    ####################################
    config:
      instance_type:
        - m5a.2xlarge
        - m5.2xlarge
        - m6i.2xlarge
        - m6a.2xlarge
        - m7i.2xlarge
        - m7a.2xlarge
      ebs_size: "3x"
      ebs_optimized: True
      spot_instance: True
      run_name: run_fastp_paired-end
      behavior_on_capacity_limit: wait_and_retry

## Alignment ################################################
#     Alignment and post-processing steps
#       to generate the final output
#############################################################

  ## Workflow definition #####################
  #   sentieon_bwa-mem_sort
  ############################################
  sentieon_bwa-mem_sort:

    ## Specific arguments ##############
    ####################################
    input:

      # File argument
      input_file_r1_fastq_gz:
        argument_type: file.fastq_gz
        source: fastp_paired-end
        source_argument_name: output_file_r1_fastq_gz

      input_file_r2_fastq_gz:
        argument_type: file.fastq_gz
        source: fastp_paired-end
        source_argument_name: output_file_r2_fastq_gz

      genome_reference_fasta:
        argument_type: file.fa

      genome_reference_bwt:
        argument_type: file.bwt

    ## Output ##########################
    #     Output files for the workflow
    ####################################
    output:

      # File output
      output_file_bam:
        description: BWA-MEM output BAM
        data_category:
          - Sequencing Reads
        data_type:
          - Aligned Reads
        s3_lifecycle_category: no_storage

    ## EC2 Configuration to use ########
    ####################################
    config:
      instance_type:
        - c5.9xlarge
        - c6i.8xlarge
        - c6a.8xlarge
        - m6i.8xlarge
        - m6a.8xlarge
        - m7i.8xlarge
        - m7a.8xlarge
      ebs_size: "4x"
      ebs_optimized: True
      spot_instance: True
      run_name: run_sentieon_bwa-mem_sort
      behavior_on_capacity_limit: wait_and_retry

  ## Workflow definition #####################
  #   AddReadGroups
  ############################################
  AddReadGroups:

    ## Specific arguments ##############
    ####################################
    input:

      # File argument
      input_file_bam:
        argument_type: file.bam
        source: sentieon_bwa-mem_sort
        source_argument_name: output_file_bam

      # Parameter argument
      sample_name:
        argument_type: parameter.string

      library_id:
        argument_type: parameter.string

      nthreads:
        argument_type: parameter.integer
        value: 4

    ## Output ##########################
    #     Output files for the workflow
    ####################################
    output:

      # File output
      output_file_bam:
        description: AddReadGroups output BAM
        data_category:
          - Sequencing Reads
        data_type:
          - Aligned Reads
        s3_lifecycle_category: no_storage

    ## EC2 Configuration to use ########
    ####################################
    config:
      instance_type:
        - c5.xlarge
        - c5a.xlarge
        - m5.xlarge
        - m5a.xlarge
        - m6i.xlarge
        - m6a.xlarge
        - m7i.xlarge
        - m7a.xlarge
      ebs_size: "3.5x"
      ebs_optimized: True
      spot_instance: True
      run_name: run_AddReadGroups
      behavior_on_capacity_limit: wait_and_retry

  ## Workflow definition #####################
  #   sentieon_LocusCollector
  ############################################
  sentieon_LocusCollector:

    ## Lock shards ####################
    ####################################
    shards: [['0'], ['1'], ['2'], ['3'], ['4'], ['5'], ['6'], ['7'], ['8'], ['9'], ['10'], ['11'], ['12'], ['13'], ['14'], ['15']]
    # These shards structure needs to match the number of shards in shards_file and defined by shards_index

    ## Specific arguments ##############
    ####################################
    input:

      # File argument
      input_files_bam:
        argument_type: file.bam
        source: AddReadGroups
        source_argument_name: output_file_bam
        gather_input: 1
        # Since it works by region we mount the files
        mount: True

      # Regions
      shards_file_txt:
        argument_type: file.txt
        source_argument_name: shards_file

      shard_index:
        argument_type: parameter.array
        source_argument_name: shards_index
        input_dimension: 1

    ## Output ##########################
    #     Output files for the workflow
    ####################################
    output:

      # File output
      output_table_vcf_gz:
        description: sentieon LocusCollector output VCF
        data_category:
          - Sequencing Reads
        data_type:
          - Statistics
        s3_lifecycle_category: no_storage

    ## EC2 Configuration to use ########
    ####################################
    config:
      instance_type:
        # we may need to use larger machines if we scale up coverage
        # these have been tested for 750x WGS
        - r5.4xlarge
        - r5n.4xlarge
        - r5a.4xlarge
        - r6i.4xlarge
        - r6a.4xlarge
        - r7i.4xlarge
        - r7a.4xlarge
      ebs_size: 50
      ebs_optimized: True
      spot_instance: True
      run_name: run_sentieon_LocusCollector
      behavior_on_capacity_limit: wait_and_retry

  ## Workflow definition #####################
  #   sentieon_LocusCollector_apply
  ############################################
  sentieon_LocusCollector_apply:

    ## Lock shards ####################
    ####################################
    shards: [['0'], ['1'], ['2'], ['3'], ['4'], ['5'], ['6'], ['7'], ['8'], ['9'], ['10'], ['11'], ['12'], ['13'], ['14'], ['15']]
    # These shards structure needs to match the number of shards in shards_file and defined by shards_index

    ## Specific arguments ##############
    ####################################
    input:

      # File argument
      input_files_bam:
        argument_type: file.bam
        source: AddReadGroups
        source_argument_name: output_file_bam
        gather_input: 1
        # Since it works by region we mount the files
        mount: True

      input_tables_vcf_gz:
        argument_type: file.vcf_gz
        source: sentieon_LocusCollector
        source_argument_name: output_table_vcf_gz
        gather_input: 1
        # Since it works by region we mount the files
        mount: True

      # Regions
      shards_file_txt:
        argument_type: file.txt
        source_argument_name: shards_file

      shard_index:
        argument_type: parameter.array
        source_argument_name: shards_index
        input_dimension: 1

      optical_dup_pix_dist:
        argument_type: parameter.integer

    ## Output ##########################
    #     Output files for the workflow
    ####################################
    output:

      # File output
      output_file_bam:
        description: sentieon Dedup output BAM (shard)
        data_category:
          - Sequencing Reads
        data_type:
          - Aligned Reads
        s3_lifecycle_category: no_storage

    ## EC2 Configuration to use ########
    ####################################
    config:
      instance_type:
        - c5.9xlarge
        - c6i.8xlarge
        - c6a.8xlarge
        - m6i.8xlarge
        - m6a.8xlarge
        - m7i.8xlarge
        - m7a.8xlarge
      ebs_size: "0.2x"
      ebs_optimized: True
      spot_instance: True
      run_name: run_sentieon_LocusCollector_apply
      behavior_on_capacity_limit: wait_and_retry

  ## Workflow definition #####################
  #   shards_to_ReadGroups
  ############################################
  shards_to_ReadGroups:

    ## Specific arguments ##############
    ####################################
    input:

      # File argument
      header_file_bam:
        argument_type: file.bam
        source: AddReadGroups
        source_argument_name: output_file_bam
        # Since it only checks the header
        mount: True

      input_files_bam:
        argument_type: file.bam
        source: sentieon_LocusCollector_apply
        source_argument_name: output_file_bam
        gather_input: 1
        # Reading multiple files
        mount: True

    ## Output ##########################
    #     Output files for the workflow
    ####################################
    output:

      # File output
      output_file_bam:
        description: sentieon Dedup output BAM
        data_category:
          - Sequencing Reads
        data_type:
          - Aligned Reads
        s3_lifecycle_category: no_storage

    ## EC2 Configuration to use ########
    ####################################
    config:
      instance_type:
        - c5.xlarge
        - c5a.xlarge
        - m5.xlarge
        - m5a.xlarge
        - m6i.xlarge
        - m6a.xlarge
        - m7i.xlarge
        - m7a.xlarge
      ebs_size: 300
      # 150GB should be a good EBS size estimate per lane,
      #   if we start merging multiple lanes may need to increase
      ebs_optimized: True
      spot_instance: True
      run_name: run_shards_to_ReadGroups
      behavior_on_capacity_limit: wait_and_retry

  ## Workflow definition #####################
  #   sentieon_Realigner
  ############################################
  sentieon_Realigner:

    ## Specific arguments ##############
    ####################################
    input:

      # File argument
      input_file_bam:
        argument_type: file.bam
        source: shards_to_ReadGroups
        source_argument_name: output_file_bam

      genome_reference_fasta:
        argument_type: file.fa

      known_sites_indel:
        argument_type: file.vcf_gz

    ## Output ##########################
    #     Output files for the workflow
    ####################################
    output:

      # File output
      output_file_bam:
        description: sentieon Realigner output BAM
        data_category:
          - Sequencing Reads
        data_type:
          - Aligned Reads
        s3_lifecycle_category: no_storage

    ## EC2 Configuration to use ########
    ####################################
    config:
      instance_type:
        - c5.9xlarge
        - c6i.8xlarge
        - c6a.8xlarge
        - m6i.8xlarge
        - m6a.8xlarge
        - m7i.8xlarge
        - m7a.8xlarge
      ebs_size: "3.5x"
      ebs_optimized: True
      spot_instance: True
      run_name: run_sentieon_Realigner
      behavior_on_capacity_limit: wait_and_retry

  ## Workflow definition #####################
  #   sentieon_QualCal
  ############################################
  sentieon_QualCal:

    ## Specific arguments ##############
    ####################################
    input:

      # File argument
      input_file_bam:
        argument_type: file.bam
        source: sentieon_Realigner
        source_argument_name: output_file_bam

      genome_reference_fasta:
        argument_type: file.fa

      known_sites_snp:
        argument_type: file.vcf_gz

      known_sites_indel:
        argument_type: file.vcf_gz

    ## Output ##########################
    #     Output files for the workflow
    ####################################
    output:

      # File output
      output_file_bam:
        description: sentieon QualCal output BAM
        data_category:
          - Sequencing Reads
        data_type:
          - Aligned Reads
        s3_lifecycle_category: no_storage

    ## EC2 Configuration to use ########
    ####################################
    config:
      instance_type:
        - c5.9xlarge
        - c6i.8xlarge
        - c6a.8xlarge
        - m6i.8xlarge
        - m6a.8xlarge
        - m7i.8xlarge
        - m7a.8xlarge
      ebs_size: "5x"
      ebs_optimized: True
      spot_instance: True
      run_name: run_sentieon_QualCal
      behavior_on_capacity_limit: wait_and_retry

  ## Workflow definition #####################
  #   samtools_merge
  ############################################
  samtools_merge:

    ## Specific arguments ##############
    ####################################
    input:

      # File argument
      input_files_bam:
        argument_type: file.bam
        source: sentieon_QualCal
        source_argument_name: output_file_bam
        gather: 1

      # Parameter argument
      nthreads:
        argument_type: parameter.integer
        value: 4

    ## Output ##########################
    #     Output files for the workflow
    ####################################
    output:

      # File output
      output_file_bam:
        description: analysis-ready BAM
        data_category:
          - Sequencing Reads
        data_type:
          - Aligned Reads
        s3_lifecycle_category: no_storage

    ## EC2 Configuration to use ########
    ####################################
    config:
      instance_type:
        - c5.xlarge
        - c5a.xlarge
        - m5.xlarge
        - m5a.xlarge
        - m6i.xlarge
        - m6a.xlarge
        - m7i.xlarge
        - m7a.xlarge
      ebs_size: "3x"
      ebs_optimized: True
      spot_instance: False
      run_name: run_samtools_merge
      behavior_on_capacity_limit: wait_and_retry

  ## Workflow definition #####################
  #   bam_to_cram
  ############################################
  bam_to_cram:

    ## Workflow arguments ##############
    ####################################
    input:

      input_file_bam:
        argument_type: file.bam
        source: samtools_merge
        source_argument_name: output_file_bam

      genome_reference_fasta:
        argument_type: file.fa

    ## Output ##########################
    ####################################
    output:

      output_file_cram:
        description: analysis-ready CRAM (from BAM)
        data_category:
          - Sequencing Reads
        data_type:
          - Aligned Reads
        output_status: Final Output
        # These fields are required to link metadata for the naming
        software:
          - smaht:Software-Sentieon_BWA-MEM_202308.01
        alignment_details:
          - Sorted
        reference_genome: GRCh38

    ## EC2 Configuration to use ########
    ####################################
    config:
      instance_type:
        - c5.xlarge
        - m5a.xlarge
        - m5.xlarge
        - m6i.xlarge
        - m6a.xlarge
        - m7i.xlarge
        - m7a.xlarge
      ebs_size: "2.5x"
      ebs_optimized: True
      spot_instance: True
      run_name: run_bam_to_cram
      behavior_on_capacity_limit: wait_and_retry

## Quality Controls #########################################
#     Steps to calculate quality metrics for
#       the final output
#############################################################

  ## Workflow definition #####################
  ############################################
  samtools_stats:

    ## Specific arguments ##############
    ####################################
    input:

      # File argument
      input_file_bam:
        argument_type: file.bam
        source: samtools_merge
        source_argument_name: output_file_bam

      # Parameter argument
      nthreads:
        argument_type: parameter.integer
        value: 2

    ## Output ##########################
    ####################################
    output:

      # File output
      output_file_txt:
        description: samtools stats output TXT
        data_category:
          - Quality Control
        data_type:
          - Statistics

    ## EC2 Configuration to use ########
    ####################################
    config:
      instance_type:
        - m5a.large
        - m5.large
        - m6i.large
        - m6a.large
        - m7i.large
        - m7a.large
      ebs_size: "1.1x"
      ebs_optimized: True
      spot_instance: True
      run_name: run_samtools_stats
      behavior_on_capacity_limit: wait_and_retry

  ## Workflow definition #####################
  ############################################
  samtools_flagstat:

    ## Specific arguments ##############
    ####################################
    input:

      # File argument
      input_file_bam:
        argument_type: file.bam
        source: samtools_merge
        source_argument_name: output_file_bam

      # Parameter argument
      nthreads:
        argument_type: parameter.integer
        value: 2

    ## Output ##########################
    ####################################
    output:

      # File output
      output_file_txt:
        description: samtools flagstat output TXT
        data_category:
          - Quality Control
        data_type:
          - Statistics

    ## EC2 Configuration to use ########
    ####################################
    config:
      instance_type:
        - m5a.large
        - m5.large
        - m6i.large
        - m6a.large
        - m7i.large
        - m7a.large
      ebs_size: "1.1x"
      ebs_optimized: True
      spot_instance: True
      run_name: run_samtools_flagstat
      behavior_on_capacity_limit: wait_and_retry

  ## Workflow definition #####################
  ############################################
  samtools_idxstats:

    ## Specific arguments ##############
    ####################################
    input:

      # File argument
      input_file_bam:
        argument_type: file.bam
        source: samtools_merge
        source_argument_name: output_file_bam
        # We only need the index file
        mount: True

    ## Output ##########################
    ####################################
    output:

      # File output
      output_file_txt:
        description: samtools idxstats output TXT
        data_category:
          - Quality Control
        data_type:
          - Statistics

    ## EC2 Configuration to use ########
    ####################################
    config:
      instance_type:
        - t3.small
      ebs_size: "1.1x"
      ebs_optimized: True
      spot_instance: True
      run_name: run_samtools_idxstats
      behavior_on_capacity_limit: wait_and_retry

  ## Workflow definition #####################
  ############################################
  picard_CollectAlignmentSummaryMetrics:

    ## Specific arguments ##############
    ####################################
    input:

      # File argument
      input_file_bam:
        argument_type: file.bam
        source: samtools_merge
        source_argument_name: output_file_bam

      genome_reference_fasta:
        argument_type: file.fa

    ## Output ##########################
    ####################################
    output:

      # File output
      output_file_txt:
        description: picard CollectAlignmentSummaryMetrics output TXT
        data_category:
          - Quality Control
        data_type:
          - Statistics

    ## EC2 Configuration to use ########
    ####################################
    config:
      instance_type:
        - m5a.large
        - m5.large
        - m6i.large
        - m6a.large
        - m7i.large
        - m7a.large
      ebs_size: "1.1x"
      ebs_optimized: True
      spot_instance: True
      run_name: run_picard_CollectAlignmentSummaryMetrics
      behavior_on_capacity_limit: wait_and_retry

  ## Workflow definition #####################
  ############################################
  picard_CollectBaseDistributionByCycle:

    ## Specific arguments ##############
    ####################################
    input:

      # File argument
      input_file_bam:
        argument_type: file.bam
        source: samtools_merge
        source_argument_name: output_file_bam

    ## Output ##########################
    ####################################
    output:

      # File output
      output_file_txt:
        description: picard CollectBaseDistributionByCycle output TXT
        data_category:
          - Quality Control
        data_type:
          - Statistics

      output_chart_pdf:
        description: picard CollectBaseDistributionByCycle output PDF
        data_category:
          - Quality Control
        data_type:
          - Image

    ## EC2 Configuration to use ########
    ####################################
    config:
      instance_type:
        - m5a.large
        - m5.large
        - m6i.large
        - m6a.large
        - m7i.large
        - m7a.large
      ebs_size: "1.1x"
      ebs_optimized: True
      spot_instance: True
      run_name: run_picard_CollectBaseDistributionByCycle
      behavior_on_capacity_limit: wait_and_retry

  ## Workflow definition #####################
  ############################################
  picard_CollectGcBiasMetrics:

    ## Specific arguments ##############
    ####################################
    input:

      # File argument
      input_file_bam:
        argument_type: file.bam
        source: samtools_merge
        source_argument_name: output_file_bam
        # extracts selected chromosomes
        # and the processing is sequential
        mount: True

      genome_reference_fasta:
        argument_type: file.fa

      nthreads:
        argument_type: parameter.integer
        value: 4

    ## Output ##########################
    ####################################
    output:

      # File output
      output_file_txt:
        description: picard CollectGcBiasMetrics output TXT
        data_category:
          - Quality Control
        data_type:
          - Statistics

      output_summary_txt:
        description: picard CollectGcBiasMetrics summary TXT
        data_category:
          - Quality Control
        data_type:
          - Statistics

      output_chart_pdf:
        description: picard CollectGcBiasMetrics output PDF
        data_category:
          - Quality Control
        data_type:
          - Image

    ## EC2 Configuration to use ########
    ####################################
    config:
      instance_type:
        - m5a.xlarge
        - m5.xlarge
        - m6i.xlarge
        - m6a.xlarge
        - m7i.xlarge
        - m7a.xlarge
      ebs_size: "1.5x"
      ebs_optimized: True
      spot_instance: False
      run_name: run_picard_CollectGcBiasMetrics
      behavior_on_capacity_limit: wait_and_retry

  ## Workflow definition #####################
  ############################################
  picard_CollectInsertSizeMetrics:

    ## Specific arguments ##############
    ####################################
    input:

      # File argument
      input_file_bam:
        argument_type: file.bam
        source: samtools_merge
        source_argument_name: output_file_bam

    ## Output ##########################
    ####################################
    output:

      # File output
      output_file_txt:
        description: picard CollectInsertSizeMetrics output TXT
        data_category:
          - Quality Control
        data_type:
          - Statistics

      output_histogram_pdf:
        description: picard CollectInsertSizeMetrics output PDF
        data_category:
          - Quality Control
        data_type:
          - Image

    ## EC2 Configuration to use ########
    ####################################
    config:
      instance_type:
        - m5a.2xlarge
        - m5.2xlarge
        - m6i.2xlarge
        - m6a.2xlarge
        - m7i.2xlarge
        - m7a.2xlarge
      ebs_size: "1.1x"
      ebs_optimized: True
      spot_instance: True
      run_name: run_picard_CollectInsertSizeMetrics
      behavior_on_capacity_limit: wait_and_retry

  ## Workflow definition #####################
  ############################################
  picard_CollectWgsMetrics:

    ## Specific arguments ##############
    ####################################
    input:

      # File argument
      input_file_bam:
        argument_type: file.bam
        source: samtools_merge
        source_argument_name: output_file_bam
        # only processes chromosome 22
        # and the processing is sequential
        mount: True

      genome_reference_fasta:
        argument_type: file.fa

      interval_list:
        argument_type: file.interval_list

      # Parameter argument
      read_length:
        argument_type: parameter.integer
        source_argument_name: length_required

    ## Output ##########################
    ####################################
    output:

      # File output
      output_file_txt:
        description: picard CollectWgsMetrics output TXT
        data_category:
          - Quality Control
        data_type:
          - Statistics

    ## EC2 Configuration to use ########
    ####################################
    config:
      instance_type:
        - r5.large
        - r5n.large
        - r5a.large
        - r6i.large
        - r6a.large
        - r7i.large
        - r7a.large
      ebs_size: "1.1x"
      ebs_optimized: True
      spot_instance: False
      run_name: run_picard_CollectWgsMetrics
      behavior_on_capacity_limit: wait_and_retry

  ## Workflow definition #####################
  ############################################
  picard_MeanQualityByCycle:

    ## Specific arguments ##############
    ####################################
    input:

      # File argument
      input_file_bam:
        argument_type: file.bam
        source: samtools_merge
        source_argument_name: output_file_bam

    ## Output ##########################
    ####################################
    output:

      # File output
      output_file_txt:
        description: picard MeanQualityByCycle output TXT
        data_category:
          - Quality Control
        data_type:
          - Statistics

      output_chart_pdf:
        description: picard MeanQualityByCycle output PDF
        data_category:
          - Quality Control
        data_type:
          - Image

    ## EC2 Configuration to use ########
    ####################################
    config:
      instance_type:
        - m5a.large
        - m5.large
        - m6i.large
        - m6a.large
        - m7i.large
        - m7a.large
      ebs_size: "1.1x"
      ebs_optimized: True
      spot_instance: True
      run_name: run_picard_MeanQualityByCycle
      behavior_on_capacity_limit: wait_and_retry

  ## Workflow definition #####################
  ############################################
  bamstats:

    ## Specific arguments ##############
    ####################################
    input:

      # File argument
      input_file_bam:
        argument_type: file.bam
        source: samtools_merge
        source_argument_name: output_file_bam

    ## Output ##########################
    ####################################
    output:

      # File output
      output_file_txt:
        description: bamstats output TXT
        data_category:
          - Quality Control
        data_type:
          - Statistics

    ## EC2 Configuration to use ########
    ####################################
    config:
      instance_type:
        - m5a.large
        - m5.large
        - m6i.large
        - m6a.large
        - m7i.large
        - m7a.large
      ebs_size: "1.1x"
      ebs_optimized: True
      spot_instance: True
      run_name: run_bamstats
      behavior_on_capacity_limit: wait_and_retry

  ## Workflow definition #####################
  ############################################
  verifybamid2:

    ## Specific arguments ##############
    ####################################
    input:

      # File arguments
      input_file_bam:
        argument_type: file.bam
        source: samtools_merge
        source_argument_name: output_file_bam

      genome_reference_fasta:
        argument_type: file.fa

      resources_vb2:
        argument_type: file.vb2

      # Parameter arguments
      nthreads:
        argument_type: parameter.integer
        value: 2

    ## Output ##########################
    ####################################
    output:

      # File output
      output_file_txt:
        description: VerifyBamID2 output TXT
        data_category:
          - Quality Control
        data_type:
          - Statistics

    ## EC2 Configuration to use ########
    ####################################
    config:
      instance_type:
        - m5a.large
        - m5.large
        - m6i.large
        - m6a.large
        - m7i.large
        - m7a.large
      ebs_size: "1.1x"
      ebs_optimized: True
      spot_instance: True
      run_name: run_verifybamid2
      behavior_on_capacity_limit: wait_and_retry

  ## Workflow definition #####################
  ############################################
  mosdepth:

    ## Specific arguments ##############
    ####################################
    input:

      # File arguments
      input_file_bam:
        argument_type: file.bam
        source: samtools_merge
        source_argument_name: output_file_bam

      # Parameter arguments
      nthreads:
        argument_type: parameter.integer
        value: 4

    ## Output ##########################
    ####################################
    output:

      # File output
      output_summary_txt:
        description: mosdepth summary TXT
        data_category:
          - Quality Control
        data_type:
          - Statistics

      output_file_txt:
        description: mosdepth output TXT
        data_category:
          - Quality Control
        data_type:
          - Statistics

    ## EC2 Configuration to use ########
    ####################################
    config:
      instance_type:
        - m5a.xlarge
        - m5.xlarge
        - m6i.xlarge
        - m6a.xlarge
        - m7i.xlarge
        - m7a.xlarge
      ebs_size: "1.1x"
      ebs_optimized: True
      spot_instance: True
      run_name: run_mosdepth
      behavior_on_capacity_limit: wait_and_retry

  ## Workflow definition #####################
  #   parse-qc_BAM_Quality_Metrics_paired-end
  ############################################
  parse-qc_BAM_Quality_Metrics_paired-end:

    ## Specific arguments ##############
    ####################################
    input:

      # File argument
      input_file_bam:
        argument_type: file.bam
        source: bam_to_cram
        source_argument_name: output_file_cram
        mount: True
        # this file is actually not used by the code but is needed
        #   to specify where the quality metrics object need to be linked

      SAMTOOLS_stats_OUTPUT:
        argument_type: file.txt
        source: samtools_stats
        source_argument_name: output_file_txt

      SAMTOOLS_flagstat_OUTPUT:
        argument_type: file.txt
        source: samtools_flagstat
        source_argument_name: output_file_txt

      SAMTOOLS_idxstats_OUTPUT:
        argument_type: file.txt
        source: samtools_idxstats
        source_argument_name: output_file_txt

      PICARD_CollectAlignmentSummaryMetrics_OUTPUT:
        argument_type: file.txt
        source: picard_CollectAlignmentSummaryMetrics
        source_argument_name: output_file_txt

      PICARD_CollectBaseDistributionByCycle_OUTPUT:
        argument_type: file.txt
        source: picard_CollectBaseDistributionByCycle
        source_argument_name: output_file_txt

      PICARD_CollectBaseDistributionByCycle_PDF:
        argument_type: file.pdf
        source: picard_CollectBaseDistributionByCycle
        source_argument_name: output_chart_pdf

      PICARD_CollectGcBiasMetrics_OUTPUT:
        argument_type: file.txt
        source: picard_CollectGcBiasMetrics
        source_argument_name: output_file_txt

      PICARD_CollectGcBiasMetrics_SUMMARY:
        argument_type: file.txt
        source: picard_CollectGcBiasMetrics
        source_argument_name: output_summary_txt

      PICARD_CollectGcBiasMetrics_PDF:
        argument_type: file.pdf
        source: picard_CollectGcBiasMetrics
        source_argument_name: output_chart_pdf

      PICARD_CollectInsertSizeMetrics_OUTPUT:
        argument_type: file.txt
        source: picard_CollectInsertSizeMetrics
        source_argument_name: output_file_txt

      PICARD_CollectInsertSizeMetrics_PDF:
        argument_type: file.pdf
        source: picard_CollectInsertSizeMetrics
        source_argument_name: output_histogram_pdf

      PICARD_CollectWgsMetrics_OUTPUT:
        argument_type: file.txt
        source: picard_CollectWgsMetrics
        source_argument_name: output_file_txt

      PICARD_MeanQualityByCycle_OUTPUT:
        argument_type: file.txt
        source: picard_MeanQualityByCycle
        source_argument_name: output_file_txt

      PICARD_MeanQualityByCycle_PDF:
        argument_type: file.pdf
        source: picard_MeanQualityByCycle
        source_argument_name: output_chart_pdf

      BAMSTATS_OUTPUT:
        argument_type: file.txt
        source: bamstats
        source_argument_name: output_file_txt

      VERIFYBAMID2_OUTPUT:
        argument_type: file.txt
        source: verifybamid2
        source_argument_name: output_file_txt

      MOSDEPTH_SUMMARY:
        argument_type: file.txt
        source: mosdepth
        source_argument_name: output_summary_txt

      MOSDEPTH_OUTPUT:
        argument_type: file.txt
        source: mosdepth
        source_argument_name: output_file_txt

      # QC ruleset arguments
      qc_ruleset:
        argument_type: qc_ruleset.object

    ## Output ##########################
    ####################################
    output:

      # File output
      qc_values_json:
        description: QC output JSON
        data_category:
          - Quality Control
        data_type:
          - Statistics

      metrics_zip:
        description: QC compressed output
        data_category:
          - Quality Control
        data_type:
          - Statistics
          - Image

    ## EC2 Configuration to use ########
    ####################################
    config:
      instance_type:
        - t3.small
      ebs_size: 10
      ebs_optimized: True
      spot_instance: True
      run_name: run_parse-qc_BAM_Quality_Metrics_paired-end
      behavior_on_capacity_limit: wait_and_retry
