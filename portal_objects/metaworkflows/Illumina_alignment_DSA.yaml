## Pipeline information #####################################
#     General information for the pipeline
#############################################################
name: Illumina_alignment_DSA
description: End-to-end alignment pipeline for paired-end Illumina data. |
             Run fastp to pre-process input FASTQ files and remove polyG artifacts. |
             Run Sentieon BWA-MEM for alignment, incorporate read groups, |
             and mark duplicate reads. |
             Sort the alignment BAM files by coordinates. |
             Merge the aligned BAM files. |
             Implemented to run in distributed mode and |
             processing reads by lane, per single sample and library. |
             Build to support DSA as the reference genome

category:
  - Read Manipulation
  - Alignment
  - Quality Control

## General arguments ########################################
#     Pipeline input, reference files, and general arguments
#       define all arguments for the pipeline here
#############################################################
input:

  # File arguments
  input_files_r1_fastq_gz:
    argument_type: file.fastq_gz
    dimensionality: 1

  input_files_r2_fastq_gz:
    argument_type: file.fastq_gz
    dimensionality: 1

  # !! FASTQ files need to be organized by lanes as the following example:
  # -> input_files_r1_fastq_gz
  #   [ lane_0_r1, lane_1_r1, lane_2_r1, ... ]
  # -> input_files_r2_fastq_gz
  #   [ lane_0_r2, lane_1_r2, lane_2_r2, ... ]

  genome_reference_fasta:
    argument_type: file.fa
    files:
    # GRCh38 is the default, change to correct DSA reference
      - complete-reference-fasta-no-alt@GCA_000001405.15_GRCh38_no_decoy

  genome_reference_bwt:
    argument_type: file.bwt
    files:
    # GRCh38 is the default, change to correct DSA reference
      - complete-reference-bwt-no-alt@GCA_000001405.15_GRCh38_no_decoy

  shards_file:
    argument_type: file.txt
    # This needs to have 16 shards to match the pipeline structure
    #   and the number of shards defined in shards_index.
    files:
    # GRCh38 is the default, change to correct DSA reference
      - regions-200M-16shards@GCA_000001405.15_GRCh38_no_decoy

  # Parameter arguments
  sample_name:
    argument_type: parameter.string

  library_id:
    argument_type: parameter.string

  length_required:
    # Reads shorter than length_required will be discarded
    argument_type: parameter.integer

  shards_index:
    # These indexes need to match the number of shards in shards_file
    argument_type: parameter.array
    value: ["0", "1", "2", "3", "4", "5", "6", "7", "8", "9", "10", "11", "12", "13", "14", "15"]

  optical_dup_pix_dist:
    # The maximum offset between two duplicate clusters in order to consider them optical duplicates.
    # This should be set to 100 for (circa 2011+) read names and typical flowcells.
    # Structured flow cells (NovaSeq, HiSeq 4000, X) should use ~2500.
    # For older conventions, distances could be to some fairly small number (e.g. 5-10 pixels).
    argument_type: parameter.integer
    value: 2500

## Workflows and dependencies ###############################
#     Information for the workflows and their dependencies
#############################################################
workflows:

## Pre-processing ###########################################
#     Steps to pre-process input files
#       for alignment
#############################################################

  ## Workflow definition #####################
  #   fastp_paired-end
  ############################################
  fastp_paired-end:

    ## Specific arguments ##############
    ####################################
    input:

      # File argument
      input_file_r1_fastq_gz:
        argument_type: file.fastq_gz
        source_argument_name: input_files_r1_fastq_gz
        scatter: 1

      input_file_r2_fastq_gz:
        argument_type: file.fastq_gz
        source_argument_name: input_files_r2_fastq_gz
        scatter: 1

      # Parameter argument
      trim_poly_g:
        # Force polyG tail trimming
        argument_type: parameter.boolean
        value: True

      disable_quality_filtering:
        # If this option is specified, quality filtering is disabled
        argument_type: parameter.boolean
        value: True

      disable_adapter_trimming:
        # If this option is specified, adapter trimming is disabled
        argument_type: parameter.boolean
        value: True

      length_required:
        argument_type: parameter.integer

      nthreads:
        argument_type: parameter.integer
        value: 16

    ## Output ##########################
    #     Output files for the workflow
    ####################################
    output:

      # File output
      output_file_r1_fastq_gz:
        description: fastp pre-processed FASTQ
        read_pair_number: "R1"
        data_category:
          - Sequencing Reads
        data_type:
          - Unaligned Reads
        s3_lifecycle_category: no_storage

      output_file_r2_fastq_gz:
        description: fastp pre-processed FASTQ
        read_pair_number: "R2"
        data_category:
          - Sequencing Reads
        data_type:
          - Unaligned Reads
        s3_lifecycle_category: no_storage

      output_file_json:
        description: fastp summary JSON
        data_category:
          - Quality Control
        data_type:
          - Statistics

      output_file_failed_fastq_gz:
        description: fastp failed reads FASTQ
        data_category:
          - Sequencing Reads
        data_type:
          - Unaligned Reads

    ## EC2 Configuration to use ########
    ####################################
    config:
      instance_type:
        - m5a.2xlarge
        - m5.2xlarge
        - m6i.2xlarge
        - m6a.2xlarge
        - m7i.2xlarge
        - m7a.2xlarge
      ebs_size: "3x"
      ebs_optimized: True
      spot_instance: True
      run_name: run_fastp_paired-end
      behavior_on_capacity_limit: wait_and_retry

## Alignment ################################################
#     Alignment and post-processing steps
#       to generate the final output
#############################################################

  ## Workflow definition #####################
  #   sentieon_bwa-mem_sort
  ############################################
  sentieon_bwa-mem_sort:

    ## Specific arguments ##############
    ####################################
    input:

      # File argument
      input_file_r1_fastq_gz:
        argument_type: file.fastq_gz
        source: fastp_paired-end
        source_argument_name: output_file_r1_fastq_gz

      input_file_r2_fastq_gz:
        argument_type: file.fastq_gz
        source: fastp_paired-end
        source_argument_name: output_file_r2_fastq_gz

      genome_reference_fasta:
        argument_type: file.fa

      genome_reference_bwt:
        argument_type: file.bwt

    ## Output ##########################
    #     Output files for the workflow
    ####################################
    output:

      # File output
      output_file_bam:
        description: BWA-MEM output BAM
        data_category:
          - Sequencing Reads
        data_type:
          - Aligned Reads
        s3_lifecycle_category: no_storage

    ## EC2 Configuration to use ########
    ####################################
    config:
      instance_type:
        - c5.9xlarge
        - c6i.8xlarge
        - c6a.8xlarge
        - m6i.8xlarge
        - m6a.8xlarge
        - m7i.8xlarge
        - m7a.8xlarge
      ebs_size: "4x"
      ebs_optimized: True
      spot_instance: True
      run_name: run_sentieon_bwa-mem_sort
      behavior_on_capacity_limit: wait_and_retry

  ## Workflow definition #####################
  #   AddReadGroups
  ############################################
  AddReadGroups:

    ## Specific arguments ##############
    ####################################
    input:

      # File argument
      input_file_bam:
        argument_type: file.bam
        source: sentieon_bwa-mem_sort
        source_argument_name: output_file_bam

      # Parameter argument
      sample_name:
        argument_type: parameter.string

      library_id:
        argument_type: parameter.string

      nthreads:
        argument_type: parameter.integer
        value: 4

    ## Output ##########################
    #     Output files for the workflow
    ####################################
    output:

      # File output
      output_file_bam:
        description: AddReadGroups output BAM
        data_category:
          - Sequencing Reads
        data_type:
          - Aligned Reads
        s3_lifecycle_category: no_storage

    ## EC2 Configuration to use ########
    ####################################
    config:
      instance_type:
        - c5.xlarge
        - c5a.xlarge
        - m5.xlarge
        - m5a.xlarge
        - m6i.xlarge
        - m6a.xlarge
        - m7i.xlarge
        - m7a.xlarge
      ebs_size: "3.5x"
      ebs_optimized: True
      spot_instance: True
      run_name: run_AddReadGroups
      behavior_on_capacity_limit: wait_and_retry

  ## Workflow definition #####################
  #   sentieon_LocusCollector
  ############################################
  sentieon_LocusCollector:

    ## Lock shards ####################
    ####################################
    shards: [['0'], ['1'], ['2'], ['3'], ['4'], ['5'], ['6'], ['7'], ['8'], ['9'], ['10'], ['11'], ['12'], ['13'], ['14'], ['15']]
    # These shards structure needs to match the number of shards in shards_file and defined by shards_index

    ## Specific arguments ##############
    ####################################
    input:

      # File argument
      input_files_bam:
        argument_type: file.bam
        source: AddReadGroups
        source_argument_name: output_file_bam
        gather_input: 1
        # Since it works by region we mount the files
        mount: True

      # Regions
      shards_file_txt:
        argument_type: file.txt
        source_argument_name: shards_file

      shard_index:
        argument_type: parameter.array
        source_argument_name: shards_index
        input_dimension: 1

    ## Output ##########################
    #     Output files for the workflow
    ####################################
    output:

      # File output
      output_table_vcf_gz:
        description: sentieon LocusCollector output VCF
        data_category:
          - Sequencing Reads
        data_type:
          - Statistics
        s3_lifecycle_category: no_storage

    ## EC2 Configuration to use ########
    ####################################
    config:
      instance_type:
        # we may need to use larger machines if we scale up coverage
        # these have been tested for 750x WGS
        - r5.4xlarge
        - r5n.4xlarge
        - r5a.4xlarge
        - r6i.4xlarge
        - r6a.4xlarge
        - r7i.4xlarge
        - r7a.4xlarge
      ebs_size: 50
      ebs_optimized: True
      spot_instance: True
      run_name: run_sentieon_LocusCollector
      behavior_on_capacity_limit: wait_and_retry

  ## Workflow definition #####################
  #   sentieon_LocusCollector_apply
  ############################################
  sentieon_LocusCollector_apply:

    ## Lock shards ####################
    ####################################
    shards: [['0'], ['1'], ['2'], ['3'], ['4'], ['5'], ['6'], ['7'], ['8'], ['9'], ['10'], ['11'], ['12'], ['13'], ['14'], ['15']]
    # These shards structure needs to match the number of shards in shards_file and defined by shards_index

    ## Specific arguments ##############
    ####################################
    input:

      # File argument
      input_files_bam:
        argument_type: file.bam
        source: AddReadGroups
        source_argument_name: output_file_bam
        gather_input: 1
        # Since it works by region we mount the files
        mount: True

      input_tables_vcf_gz:
        argument_type: file.vcf_gz
        source: sentieon_LocusCollector
        source_argument_name: output_table_vcf_gz
        gather_input: 1
        # Since it works by region we mount the files
        mount: True

      # Regions
      shards_file_txt:
        argument_type: file.txt
        source_argument_name: shards_file

      shard_index:
        argument_type: parameter.array
        source_argument_name: shards_index
        input_dimension: 1

      optical_dup_pix_dist:
        argument_type: parameter.integer

    ## Output ##########################
    #     Output files for the workflow
    ####################################
    output:

      # File output
      output_file_bam:
        description: sentieon Dedup output BAM (shard)
        data_category:
          - Sequencing Reads
        data_type:
          - Aligned Reads
        s3_lifecycle_category: no_storage

    ## EC2 Configuration to use ########
    ####################################
    config:
      instance_type:
        - c5.9xlarge
        - c6i.8xlarge
        - c6a.8xlarge
        - m6i.8xlarge
        - m6a.8xlarge
        - m7i.8xlarge
        - m7a.8xlarge
      ebs_size: "0.1x"
      ebs_optimized: True
      spot_instance: True
      run_name: run_sentieon_LocusCollector_apply
      behavior_on_capacity_limit: wait_and_retry

  ## Workflow definition #####################
  #   shards_to_ReadGroups
  ############################################
  shards_to_ReadGroups:

    ## Specific arguments ##############
    ####################################
    input:

      # File argument
      header_file_bam:
        argument_type: file.bam
        source: AddReadGroups
        source_argument_name: output_file_bam
        # Since it only checks the header
        mount: True

      input_files_bam:
        argument_type: file.bam
        source: sentieon_LocusCollector_apply
        source_argument_name: output_file_bam
        gather_input: 1
        # Reading multiple files
        mount: True

    ## Output ##########################
    #     Output files for the workflow
    ####################################
    output:

      # File output
      output_file_bam:
        description: sentieon Dedup output BAM
        data_category:
          - Sequencing Reads
        data_type:
          - Aligned Reads
        s3_lifecycle_category: no_storage

    ## EC2 Configuration to use ########
    ####################################
    config:
      instance_type:
        - c5.xlarge
        - c5a.xlarge
        - m5.xlarge
        - m5a.xlarge
        - m6i.xlarge
        - m6a.xlarge
        - m7i.xlarge
        - m7a.xlarge
      ebs_size: 150
      # 150GB should be a good EBS size estimate per lane,
      #   if we start merging multiple lanes may need to increase
      ebs_optimized: True
      spot_instance: True
      run_name: run_shards_to_ReadGroups
      behavior_on_capacity_limit: wait_and_retry

  ## Workflow definition #####################
  #   samtools_merge
  ############################################
  samtools_merge:

    ## Specific arguments ##############
    ####################################
    input:

      # File argument
      input_files_bam:
        argument_type: file.bam
        source: shards_to_ReadGroups
        source_argument_name: output_file_bam
        gather: 1

      # Parameter argument
      nthreads:
        argument_type: parameter.integer
        value: 4

    ## Output ##########################
    #     Output files for the workflow
    ####################################
    output:

      # File output
      output_file_bam:
        description: analysis-ready BAM
        data_category:
          - Sequencing Reads
        data_type:
          - Aligned Reads
        output_status: Final Output
        # These fields are required to link metadata for the naming
        software:
          - smaht:Software-Sentieon_BWA-MEM_202308.01
        alignment_details:
          - Sorted

    ## EC2 Configuration to use ########
    ####################################
    config:
      instance_type:
        - c5.xlarge
        - c5a.xlarge
        - m5.xlarge
        - m5a.xlarge
        - m6i.xlarge
        - m6a.xlarge
        - m7i.xlarge
        - m7a.xlarge
      ebs_size: "3x"
      ebs_iops: 16000
      ebs_throughput: 1000
      ebs_optimized: True
      spot_instance: False
      run_name: run_samtools_merge
      behavior_on_capacity_limit: wait_and_retry
